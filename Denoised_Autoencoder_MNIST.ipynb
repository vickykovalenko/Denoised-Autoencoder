{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OSShiRCE52dR"
   },
   "outputs": [],
   "source": [
    "#!pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSiweT0o5YKv"
   },
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "VaYCy1Vd5oKh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pl_qS4aK5fYQ"
   },
   "source": [
    "Loading MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "QlRC4XOB5zfl"
   },
   "outputs": [],
   "source": [
    "## transformations\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "#transform = transforms.Compose([\n",
    "#            transforms.ToTensor(),\n",
    "#            transforms.Normalize((0.5), (0.5))                    \n",
    "#])\n",
    "\n",
    "## download and load training dataset\n",
    "mnist_data = datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "## download and load training dataset\n",
    "trainset = datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True)\n",
    "\n",
    "## download and load testing dataset\n",
    "testset = datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxYHviSz5xnl"
   },
   "source": [
    "Autoencoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "aJ1i2K1pSRuX"
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        # N, 1, 28, 28\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1), # -> N, 16, 14, 14\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1), # -> N, 32, 7, 7\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 7) # -> N, 64, 1, 1\n",
    "        )\n",
    "        \n",
    "        # N , 64, 1, 1\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 7), # -> N, 32, 7, 7\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), # N, 16, 14, 14 (N,16,13,13 without output_padding)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1), # N, 1, 28, 28  (N,1,27,27)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "# Note : [-1, -1] -> nn.Tanh\n",
    "# nn.MaxPool2d -> nn.MaxUnpool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "xAncGoVh_vgT"
   },
   "outputs": [],
   "source": [
    "model = Autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrRXQdKm53Rz"
   },
   "source": [
    "Training Autoencoder model with denoized digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "54BQkWCcA3tm"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, train_dl, epochs=5, device='cpu'):\n",
    "    noise_factor=0.5\n",
    "    outputs = []\n",
    "    for epoch in range(epochs):\n",
    "        for (img, _) in train_dl:\n",
    "            #img = img.reshape(-1, 28*28)  use for Autoencoder_Linear\n",
    "\n",
    "            ## add random noise to the input images\n",
    "            noisy_imgs = img + noise_factor * torch.randn(*img.shape)\n",
    "            # Clip the images to be between 0 and 1\n",
    "            noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
    "\n",
    "            recon = model(noisy_imgs) # reconstructed image\n",
    "            loss = loss_fn(recon, img) # \n",
    "\n",
    "            optimizer.zero_grad() # do not forget about this step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')\n",
    "        outputs.append((epoch, img, recon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mkeZDVaA164j",
    "outputId": "d89f790d-031d-485a-a630-230e886103db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Loss:0.0248\n",
      "Epoch:2, Loss:0.0155\n",
      "Epoch:3, Loss:0.0151\n",
      "Epoch:4, Loss:0.0123\n",
      "Epoch:5, Loss:0.0121\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWlBOpG76M8g"
   },
   "source": [
    "Testing the trained autoencoder model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "8Xk8iiFkopKD"
   },
   "outputs": [],
   "source": [
    "def inference(model, testloader):\n",
    "    # obtain one batch of test images\n",
    "    noise_factor=0.5\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    # add noise to the test images\n",
    "    noisy_imgs = images + noise_factor * torch.randn(*images.shape)\n",
    "    noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
    "\n",
    "    # get sample outputs\n",
    "    output = model(noisy_imgs)\n",
    "    # prep images for display\n",
    "    noisy_imgs = noisy_imgs.numpy()\n",
    "\n",
    "    # output is resized into a batch of iages\n",
    "    output = output.view(64, 1, 28, 28)\n",
    "    # use detach when it's an output that requires_grad\n",
    "    output = output.detach().numpy()\n",
    "\n",
    "    '''# plot the first ten input images and then reconstructed images\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(25,4))\n",
    "\n",
    "    # input images on top row, reconstructions on bottom\n",
    "    for noisy_imgs, row in zip([noisy_imgs, output], axes):\n",
    "        for img, ax in zip(noisy_imgs, row):\n",
    "            ax.imshow(np.squeeze(img), cmap='gray')\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)'''\n",
    "\n",
    "    #plot the first ten input image and then reconstructed images\n",
    "\n",
    "    img = np.squeeze(noisy_imgs[0])\n",
    "    fig = plt.figure(figsize = (5,5)) \n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img, cmap='gray')\n",
    "\n",
    "    img2 = np.squeeze(output[0])\n",
    "    fig = plt.figure(figsize = (5,5)) \n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img2, cmap='gray')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623
    },
    "id": "eVABO8tV0tNW",
    "outputId": "106fd5cb-ae1d-47b3-d0da-d0aea82444a0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inference(model, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhV6hRq5AaC6"
   },
   "source": [
    "Classification network and eveluate efectiveness of the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "oEWtJ5XSZ3Jt"
   },
   "outputs": [],
   "source": [
    "## transformations\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "#transform = transforms.Compose([\n",
    "#            transforms.ToTensor(),\n",
    "#            transforms.Normalize((0.5), (0.5))                    \n",
    "#])\n",
    "\n",
    "## download and load training dataset\n",
    "mnist_data = datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "## download and load training dataset\n",
    "trainset = datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=20,\n",
    "                                          shuffle=True)\n",
    "\n",
    "## download and load testing dataset\n",
    "testset = datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=20,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFNCts8c64xk"
   },
   "source": [
    "Classification model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "_IYnV4ZBa3cJ"
   },
   "outputs": [],
   "source": [
    "class ClassifyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassifyModel, self).__init__()\n",
    "\n",
    "        # 28x28x1 => 26x26x32\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "        self.d1 = nn.Linear(26 * 26 * 32, 128)\n",
    "        self.d2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 32x1x28x28 => 32x32x26x26\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # flatten => 32 x (32*26*26)\n",
    "        x = x.flatten(start_dim = 1)\n",
    "\n",
    "        # 32 x (32*26*26) => 32x128\n",
    "        x = self.d1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # logits => 32x10\n",
    "        logits = self.d2(x)\n",
    "        out = F.softmax(logits, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "6M8c1crhPx55"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_classify = ClassifyModel()\n",
    "model_classify = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "mwvCpwaBP1-Y"
   },
   "outputs": [],
   "source": [
    "## compute accuracy\n",
    "def get_accuracy(logit, target, batch_size):\n",
    "    ''' Obtain accuracy for training round '''\n",
    "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100.0 * corrects/batch_size\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nz3PDRSV7ANC"
   },
   "source": [
    "Training classification model on clean train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "p2Rw4VAeQJgD"
   },
   "outputs": [],
   "source": [
    "def train_classify(model_classify, optimizer, criterion, trainloader, num_epochs=5, device='cpu'):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_running_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "\n",
    "        model_classify = model_classify.train()\n",
    "\n",
    "        ## training step\n",
    "        for i, (images, labels) in enumerate(trainloader):\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model_classify(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            ## update model params\n",
    "            optimizer.step()\n",
    "\n",
    "            train_running_loss += loss.detach().item()\n",
    "            train_acc += get_accuracy(logits, labels, 20)\n",
    "        \n",
    "        model.eval()\n",
    "        print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' \\\n",
    "              %(epoch, train_running_loss / i, train_acc/i))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sfcgiu9RzN2Q",
    "outputId": "9eb05747-9324-4a34-98e9-57eda008f234"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 1.4891 | Train Accuracy: 97.42\n",
      "Epoch: 1 | Loss: 1.4805 | Train Accuracy: 98.22\n",
      "Epoch: 2 | Loss: 1.4765 | Train Accuracy: 98.60\n",
      "Epoch: 3 | Loss: 1.4750 | Train Accuracy: 98.72\n",
      "Epoch: 4 | Loss: 1.4725 | Train Accuracy: 98.94\n"
     ]
    }
   ],
   "source": [
    "train_classify(model_classify, optimizer, criterion, trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3_lc8BU7I-L"
   },
   "source": [
    "Testing a classification model on clean test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "XeWSDFt5QPSt"
   },
   "outputs": [],
   "source": [
    "def test_classify(model_classify, testloader):\n",
    "    # initialize lists to monitor test loss and accuracy\n",
    "    test_loss = 0.0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "\n",
    "    model_classify.eval() # prep model for training\n",
    "\n",
    "    for data, target in testloader:\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model_classify(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update test loss \n",
    "        test_loss += loss.item()*data.size(0)\n",
    "        # convert output probabilities to predicted class\n",
    "        _, pred = torch.max(output, 1)\n",
    "        # compare predictions to true label\n",
    "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "        # calculate test accuracy for each object class\n",
    "        for i in range(20):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "    # calculate and print avg test loss\n",
    "    test_loss = test_loss/len(testloader.dataset)\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    for i in range(10):\n",
    "        if class_total[i] > 0:\n",
    "            print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "                str(i), 100 * class_correct[i] / class_total[i],\n",
    "                np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "        else:\n",
    "            print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "    print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "        100. * np.sum(class_correct) / np.sum(class_total),\n",
    "        np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XOawYig22Wgv",
    "outputId": "8853dbea-09a7-437a-e206-647efd5688f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.481816\n",
      "\n",
      "Test Accuracy of     0: 97% (959/980)\n",
      "Test Accuracy of     1: 99% (1130/1135)\n",
      "Test Accuracy of     2: 97% (1006/1032)\n",
      "Test Accuracy of     3: 99% (1001/1010)\n",
      "Test Accuracy of     4: 97% (962/982)\n",
      "Test Accuracy of     5: 97% (868/892)\n",
      "Test Accuracy of     6: 98% (940/958)\n",
      "Test Accuracy of     7: 98% (1012/1028)\n",
      "Test Accuracy of     8: 94% (925/974)\n",
      "Test Accuracy of     9: 97% (986/1009)\n",
      "\n",
      "Test Accuracy (Overall): 97% (9789/10000)\n"
     ]
    }
   ],
   "source": [
    "test_classify(model_classify, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxuqXX-V7UkF"
   },
   "source": [
    "Testing a classification model on noisy test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "z-PccsZMd6WW"
   },
   "outputs": [],
   "source": [
    "def test_noisy(model_classify, testloader):\n",
    "    # initialize lists to monitor test loss and accuracy\n",
    "    noise_factor=0.5\n",
    "    test_loss = 0.0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "\n",
    "    model_classify.eval() # prep model for training\n",
    "\n",
    "    for data, target in testloader:\n",
    "        \n",
    "        # add noise to the test images\n",
    "        noisy_imgs = data + noise_factor * torch.randn(*data.shape)\n",
    "        noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
    "\n",
    "        # get sample outputs\n",
    "        output = model_classify(noisy_imgs)\n",
    "      \n",
    "\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "      \n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update test loss \n",
    "        test_loss += loss.item()*data.size(0)\n",
    "        # convert output probabilities to predicted class\n",
    "        _, pred = torch.max(output, 1)\n",
    "        # compare predictions to true label\n",
    "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "        # calculate test accuracy for each object class\n",
    "        for i in range(20):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "    # calculate and print avg test loss\n",
    "    test_loss = test_loss/len(testloader.dataset)\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    for i in range(10):\n",
    "        if class_total[i] > 0:\n",
    "            print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "                str(i), 100 * class_correct[i] / class_total[i],\n",
    "                np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "        else:\n",
    "            print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "    print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "        100. * np.sum(class_correct) / np.sum(class_total),\n",
    "        np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xCfxEev52-Z1",
    "outputId": "3ef18cdd-3bc8-4a1a-8bd4-58257ee5ad88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.692330\n",
      "\n",
      "Test Accuracy of     0: 56% (550/980)\n",
      "Test Accuracy of     1: 73% (838/1135)\n",
      "Test Accuracy of     2: 88% (914/1032)\n",
      "Test Accuracy of     3: 78% (790/1010)\n",
      "Test Accuracy of     4: 94% (927/982)\n",
      "Test Accuracy of     5: 90% (807/892)\n",
      "Test Accuracy of     6: 85% (815/958)\n",
      "Test Accuracy of     7: 70% (726/1028)\n",
      "Test Accuracy of     8: 78% (765/974)\n",
      "Test Accuracy of     9: 56% (574/1009)\n",
      "\n",
      "Test Accuracy (Overall): 77% (7706/10000)\n"
     ]
    }
   ],
   "source": [
    "test_noisy(model_classify, testloader)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Denoised-Autoencoder-MNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
